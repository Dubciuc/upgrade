services:
  postgres:
    image: postgres:15
    container_name: upgrade_postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ../../database/migrations:/docker-entrypoint-initdb.d/
    ports:
      - "5432:5432"
    networks:
      - upgrade_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3

  redis:
    image: redis:7-alpine
    container_name: upgrade_redis
    command: redis-server --requirepass ${REDIS_PASSWORD}
    ports:
      - "6379:6379"
    networks:
      - upgrade_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  minio:
    image: minio/minio:latest
    container_name: upgrade_minio
    networks: [upgrade_network]
    ports:
      - "0.0.0.0:9000:9000"
      - "0.0.0.0:9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"
    volumes:
      - ./data/minio:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3


  airflow-webserver:
    image: apache/airflow:2.7.3-python3.11
    container_name: upgrade_airflow_webserver
    command: webserver
    environment:
      - AIRFLOW_UID=${AIRFLOW_UID}
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=${AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION}
      - AIRFLOW__CORE__LOAD_EXAMPLES=${AIRFLOW__CORE__LOAD_EXAMPLES}
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=${AIRFLOW__WEBSERVER__EXPOSE_CONFIG}
    volumes:
      - ../../airflow/dags:/opt/airflow/dags
      - ../../airflow/plugins:/opt/airflow/plugins
      - ../../airflow/config:/opt/airflow/config
      - airflow_logs:/opt/airflow/logs
    ports:
      - "8080:8080"
    networks:
      - upgrade_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  airflow-scheduler:
    image: apache/airflow:2.7.3-python3.11
    container_name: upgrade_airflow_scheduler
    command: scheduler
    environment:
      - AIRFLOW_UID=${AIRFLOW_UID}
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    volumes:
      - ../../airflow/dags:/opt/airflow/dags
      - ../../airflow/plugins:/opt/airflow/plugins
      - ../../airflow/config:/opt/airflow/config
      - airflow_logs:/opt/airflow/logs
    networks:
      - upgrade_network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  airflow-init:
    image: apache/airflow:2.7.3-python3.11
    container_name: upgrade_airflow_init
    command: >
      bash -c "
        airflow db init &&
        airflow users create \
          --username admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@upgrade.com \
          --password admin123
      "
    environment:
      - AIRFLOW_UID=${AIRFLOW_UID}
      - AIRFLOW__CORE__EXECUTOR=${AIRFLOW__CORE__EXECUTOR}
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}
    volumes:
      - airflow_logs:/opt/airflow/logs
    networks:
      - upgrade_network
    depends_on:
      postgres:
        condition: service_healthy
    restart: "no"

  weather-collector:
    build:
      context: ../../weather-collector
      dockerfile: Dockerfile
    container_name: upgrade_weather_collector
    environment:
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - MINIO_BUCKET=upgrade-raw
      - API_BASE_URL=https://api.open-meteo.com/v1
      - BATCH_SIZE=50
      - SAVE_JSON=true
      - SAVE_PARQUET=true
    networks:
      - upgrade_network
    depends_on:
      minio:
        condition: service_healthy
    restart: "no"

networks:
  upgrade_network:
    driver: bridge
    name: upgrade_network

volumes:
  postgres_data:
    name: upgrade_postgres_data
  minio_data:
    name: upgrade_minio_data
  airflow_logs:
    name: upgrade_airflow_logs