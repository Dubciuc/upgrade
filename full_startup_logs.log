time="2025-09-07T13:23:38Z" level=warning msg="a network with name upgrade_network exists but was not created for project \"upgrade\".\nSet `external: true` to use an existing network"
time="2025-09-07T13:23:38Z" level=warning msg="volume \"upgrade_airflow_logs\" already exists but was created for project \"docker\" (expected \"upgrade\"). Use `external: true` to use an existing volume"
time="2025-09-07T13:23:38Z" level=warning msg="volume \"upgrade_postgres_data\" already exists but was created for project \"docker\" (expected \"upgrade\"). Use `external: true` to use an existing volume"
 Container upgrade_open_meteo  Creating
 Container upgrade_zookeeper  Creating
 Container upgrade_minio  Creating
 Container upgrade_postgres  Creating
 Container upgrade_redis  Creating
 Container upgrade_minio  Created
 Container upgrade_postgres  Created
 Container upgrade_airflow_init  Creating
 Container upgrade_pgadmin  Creating
 Container upgrade_open_meteo  Created
 Container upgrade_redis  Created
 Container upgrade_airflow_webserver  Creating
 Container upgrade_zookeeper  Created
 Container upgrade_kafka  Creating
 Container upgrade_airflow_scheduler  Creating
 Container upgrade_pgadmin  Created
 Container upgrade_airflow_scheduler  Created
 Container upgrade_airflow_init  Created
 Container upgrade_airflow_webserver  Created
 Container upgrade_kafka  Created
 Container upgrade_weather_producer  Creating
 Container upgrade_weather_consumer  Creating
 Container upgrade_kafka_ui  Creating
 Container upgrade_weather_producer  Created
 Container upgrade_kafka_ui  Created
 Container upgrade_weather_consumer  Created
Attaching to upgrade_airflow_init, upgrade_airflow_scheduler, upgrade_airflow_webserver, upgrade_kafka, upgrade_kafka_ui, upgrade_minio, upgrade_open_meteo, upgrade_pgadmin, upgrade_postgres, upgrade_redis, upgrade_weather_consumer, upgrade_weather_producer, upgrade_zookeeper
upgrade_redis              | 1:C 07 Sep 2025 13:23:39.112 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
upgrade_redis              | 1:C 07 Sep 2025 13:23:39.112 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
upgrade_redis              | 1:C 07 Sep 2025 13:23:39.112 * Redis version=7.4.5, bits=64, commit=00000000, modified=0, pid=1, just started
upgrade_redis              | 1:C 07 Sep 2025 13:23:39.112 * Configuration loaded
upgrade_redis              | 1:M 07 Sep 2025 13:23:39.113 * monotonic clock: POSIX clock_gettime
upgrade_redis              | 1:M 07 Sep 2025 13:23:39.114 * Running mode=standalone, port=6379.
upgrade_redis              | 1:M 07 Sep 2025 13:23:39.114 * Server initialized
upgrade_redis              | 1:M 07 Sep 2025 13:23:39.114 * Ready to accept connections tcp
upgrade_open_meteo         | [ NOTICE ] Server started on http://0.0.0.0:8080
upgrade_postgres           | 
upgrade_postgres           | PostgreSQL Database directory appears to contain a database; Skipping initialization
upgrade_postgres           | 
upgrade_zookeeper          | ===> User
upgrade_zookeeper          | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
upgrade_zookeeper          | ===> Configuring ...
upgrade_postgres           | 2025-09-07 13:23:39.304 UTC [1] LOG:  starting PostgreSQL 15.4 (Debian 15.4-1.pgdg110+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 10.2.1-6) 10.2.1 20210110, 64-bit
upgrade_postgres           | 2025-09-07 13:23:39.304 UTC [1] LOG:  listening on IPv4 address "0.0.0.0", port 5432
upgrade_postgres           | 2025-09-07 13:23:39.304 UTC [1] LOG:  listening on IPv6 address "::", port 5432
upgrade_postgres           | 2025-09-07 13:23:39.311 UTC [1] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
upgrade_postgres           | 2025-09-07 13:23:39.321 UTC [29] LOG:  database system was shut down at 2025-09-07 13:23:25 UTC
upgrade_postgres           | 2025-09-07 13:23:39.330 UTC [1] LOG:  database system is ready to accept connections
upgrade_kafka              | ===> User
upgrade_kafka              | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
upgrade_kafka              | ===> Configuring ...
upgrade_kafka              | Running in Zookeeper mode...
upgrade_minio              | MinIO Object Storage Server
upgrade_minio              | Copyright: 2015-2025 MinIO, Inc.
upgrade_minio              | License: GNU AGPLv3 - https://www.gnu.org/licenses/agpl-3.0.html
upgrade_minio              | Version: RELEASE.2025-07-23T15-54-02Z (go1.24.5 linux/amd64)
upgrade_minio              | 
upgrade_minio              | API: http://172.20.0.4:9000  http://127.0.0.1:9000 
upgrade_minio              | WebUI: http://172.20.0.4:9001 http://127.0.0.1:9001  
upgrade_minio              | 
upgrade_minio              | Docs: https://docs.min.io
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | ERROR:__main__:Failed to initialize producer: NoBrokersAvailable
upgrade_weather_producer   | ERROR:__main__:Producer failed: NoBrokersAvailable
upgrade_weather_producer   | INFO:__main__:Cleanup completed
upgrade_kafka_ui           | Standard Commons Logging discovery in action with spring-jcl: please remove commons-logging.jar from classpath in order to avoid potential conflicts
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: NoBrokersAvailable
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 46, in initialize
upgrade_weather_consumer   |     self.consumer = KafkaConsumer(
upgrade_weather_consumer   |                     ^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/consumer/group.py", line 356, in __init__
upgrade_weather_consumer   |     self._client = KafkaClient(metrics=self._metrics, **self.config)
upgrade_weather_consumer   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 244, in __init__
upgrade_weather_consumer   |     self.config['api_version'] = self.check_version(timeout=check_timeout)
upgrade_weather_consumer   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 900, in check_version
upgrade_weather_consumer   |     raise Errors.NoBrokersAvailable()
upgrade_weather_consumer   | kafka.errors.NoBrokersAvailable: NoBrokersAvailable
[Kupgrade_weather_producer exited with code 0
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | ERROR:__main__:Failed to initialize producer: NoBrokersAvailable
upgrade_weather_producer   | ERROR:__main__:Producer failed: NoBrokersAvailable
upgrade_weather_producer   | INFO:__main__:Cleanup completed
[Kupgrade_weather_consumer exited with code 0
upgrade_kafka_ui           |  _   _ ___    __             _                _          _  __      __ _
upgrade_kafka_ui           | | | | |_ _|  / _|___ _ _    /_\  _ __ __ _ __| |_  ___  | |/ /__ _ / _| |_____
upgrade_kafka_ui           | | |_| || |  |  _/ _ | '_|  / _ \| '_ / _` / _| ' \/ -_) | ' </ _` |  _| / / _`|
upgrade_kafka_ui           |  \___/|___| |_| \___|_|   /_/ \_| .__\__,_\__|_||_\___| |_|\_\__,_|_| |_\_\__,|
upgrade_kafka_ui           |                                  |_|                                             
upgrade_kafka_ui           | 
upgrade_zookeeper          | ===> Running preflight checks ... 
upgrade_zookeeper          | ===> Check if /var/lib/zookeeper/data is writable ...
[Kupgrade_weather_producer exited with code 0
upgrade_kafka_ui           | [30m2025-09-07 13:23:41,583[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Starting KafkaUiApplication using Java 17.0.6 with PID 1 (/kafka-ui-api.jar started by kafkaui in /)
upgrade_kafka_ui           | [30m2025-09-07 13:23:41,587[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Running with Spring Boot v3.1.3, Spring v6.0.11
upgrade_kafka_ui           | [30m2025-09-07 13:23:41,588[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: No active profile set, falling back to 1 default profile: "default"
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_zookeeper          | ===> Check if /var/lib/zookeeper/log is writable ...
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | ERROR:__main__:Failed to initialize producer: NoBrokersAvailable
upgrade_weather_producer   | ERROR:__main__:Producer failed: NoBrokersAvailable
upgrade_weather_producer   | INFO:__main__:Cleanup completed
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: NoBrokersAvailable
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 46, in initialize
upgrade_weather_consumer   |     self.consumer = KafkaConsumer(
upgrade_weather_consumer   |                     ^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/consumer/group.py", line 356, in __init__
upgrade_weather_consumer   |     self._client = KafkaClient(metrics=self._metrics, **self.config)
upgrade_weather_consumer   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 244, in __init__
upgrade_weather_consumer   |     self.config['api_version'] = self.check_version(timeout=check_timeout)
upgrade_weather_consumer   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 900, in check_version
upgrade_weather_consumer   |     raise Errors.NoBrokersAvailable()
upgrade_weather_consumer   | kafka.errors.NoBrokersAvailable: NoBrokersAvailable
upgrade_zookeeper          | ===> Launching ... 
upgrade_zookeeper          | ===> Launching zookeeper ... 
[Kupgrade_weather_producer exited with code 0
upgrade_kafka              | ===> Running preflight checks ... 
upgrade_kafka              | ===> Check if /var/lib/kafka/data is writable ...
[Kupgrade_weather_consumer exited with code 0
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | ERROR:__main__:Failed to initialize producer: NoBrokersAvailable
upgrade_weather_producer   | ERROR:__main__:Producer failed: NoBrokersAvailable
upgrade_weather_producer   | INFO:__main__:Cleanup completed
upgrade_zookeeper          | [2025-09-07 13:23:42,949] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,958] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,958] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,958] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,958] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,959] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
upgrade_zookeeper          | [2025-09-07 13:23:42,959] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
upgrade_zookeeper          | [2025-09-07 13:23:42,960] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
upgrade_zookeeper          | [2025-09-07 13:23:42,960] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
upgrade_zookeeper          | [2025-09-07 13:23:42,961] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)
upgrade_zookeeper          | [2025-09-07 13:23:42,961] INFO Reading configuration from: /etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,962] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,962] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,962] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,962] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
upgrade_zookeeper          | [2025-09-07 13:23:42,962] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
upgrade_kafka              | ===> Check if Zookeeper is healthy ...
upgrade_zookeeper          | [2025-09-07 13:23:42,973] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@1fb700ee (org.apache.zookeeper.server.ServerMetrics)
upgrade_zookeeper          | [2025-09-07 13:23:42,976] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,987] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:host.name=5111fe3faea3 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.version=11.0.18 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.class.path=/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.version=5.15.0-142-generic (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:user.name=appuser (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:user.home=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:user.dir=/home/appuser (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,989] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,990] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
upgrade_zookeeper          | [2025-09-07 13:23:42,991] INFO minSessionTimeout set to 4000 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,991] INFO maxSessionTimeout set to 40000 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,992] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
upgrade_zookeeper          | [2025-09-07 13:23:42,992] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,993] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
upgrade_zookeeper          | [2025-09-07 13:23:42,996] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,996] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:42,996] INFO Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 clientPortListenBacklog -1 datadir /var/lib/zookeeper/log/version-2 snapdir /var/lib/zookeeper/data/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:43,017] INFO Logging initialized @630ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)
upgrade_zookeeper          | [2025-09-07 13:23:43,107] WARN o.e.j.s.ServletContextHandler@7eecb5b8{/,null,STOPPED} contextPath ends with /* (org.eclipse.jetty.server.handler.ContextHandler)
upgrade_zookeeper          | [2025-09-07 13:23:43,107] WARN Empty contextPath (org.eclipse.jetty.server.handler.ContextHandler)
upgrade_zookeeper          | [2025-09-07 13:23:43,127] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 11.0.18+10-LTS (org.eclipse.jetty.server.Server)
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_zookeeper          | [2025-09-07 13:23:43,156] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)
upgrade_zookeeper          | [2025-09-07 13:23:43,156] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)
upgrade_zookeeper          | [2025-09-07 13:23:43,157] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)
upgrade_zookeeper          | [2025-09-07 13:23:43,161] WARN ServletContext@o.e.j.s.ServletContextHandler@7eecb5b8{/,null,STARTING} has uncovered http methods for path: /* (org.eclipse.jetty.security.SecurityHandler)
upgrade_zookeeper          | [2025-09-07 13:23:43,174] INFO Started o.e.j.s.ServletContextHandler@7eecb5b8{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: NoBrokersAvailable
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 46, in initialize
upgrade_weather_consumer   |     self.consumer = KafkaConsumer(
upgrade_weather_consumer   |                     ^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/consumer/group.py", line 356, in __init__
upgrade_weather_consumer   |     self._client = KafkaClient(metrics=self._metrics, **self.config)
upgrade_weather_consumer   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 244, in __init__
upgrade_weather_consumer   |     self.config['api_version'] = self.check_version(timeout=check_timeout)
upgrade_weather_consumer   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 900, in check_version
upgrade_weather_consumer   |     raise Errors.NoBrokersAvailable()
upgrade_weather_consumer   | kafka.errors.NoBrokersAvailable: NoBrokersAvailable
upgrade_zookeeper          | [2025-09-07 13:23:43,199] INFO Started ServerConnector@5b247367{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} (org.eclipse.jetty.server.AbstractConnector)
upgrade_zookeeper          | [2025-09-07 13:23:43,200] INFO Started @813ms (org.eclipse.jetty.server.Server)
upgrade_zookeeper          | [2025-09-07 13:23:43,200] INFO Started AdminServer on address 0.0.0.0, port 8080 and command URL /commands (org.apache.zookeeper.server.admin.JettyAdminServer)
[Kupgrade_weather_producer exited with code 0
upgrade_zookeeper          | [2025-09-07 13:23:43,205] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,206] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,207] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 4 selector thread(s), 64 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,208] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,222] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,222] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
upgrade_zookeeper          | [2025-09-07 13:23:43,223] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
upgrade_zookeeper          | [2025-09-07 13:23:43,223] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
upgrade_zookeeper          | [2025-09-07 13:23:43,226] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
upgrade_zookeeper          | [2025-09-07 13:23:43,226] INFO Reading snapshot /var/lib/zookeeper/data/version-2/snapshot.26 (org.apache.zookeeper.server.persistence.FileSnap)
upgrade_zookeeper          | [2025-09-07 13:23:43,229] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x26, and digest value as 60758196274 (org.apache.zookeeper.server.DataTree)
upgrade_zookeeper          | [2025-09-07 13:23:43,232] INFO Snapshot loaded in 9 ms, highest zxid is 0x26, digest is 60758196274 (org.apache.zookeeper.server.ZKDatabase)
upgrade_zookeeper          | [2025-09-07 13:23:43,232] INFO Snapshotting: 0x26 to /var/lib/zookeeper/data/version-2/snapshot.26 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
upgrade_zookeeper          | [2025-09-07 13:23:43,234] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
upgrade_zookeeper          | [2025-09-07 13:23:43,242] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
upgrade_zookeeper          | [2025-09-07 13:23:43,243] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
upgrade_zookeeper          | [2025-09-07 13:23:43,259] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
upgrade_zookeeper          | [2025-09-07 13:23:43,259] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[Kupgrade_weather_consumer exited with code 1
upgrade_kafka              | [2025-09-07 13:23:43,641] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:host.name=81126b51c32b (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.class.path=/usr/share/java/cp-base-new/kafka-raft-7.4.0-ccs.jar:/usr/share/java/cp-base-new/zookeeper-jute-3.6.3.jar:/usr/share/java/cp-base-new/slf4j-api-1.7.36.jar:/usr/share/java/cp-base-new/kafka-server-common-7.4.0-ccs.jar:/usr/share/java/cp-base-new/paranamer-2.8.jar:/usr/share/java/cp-base-new/scala-java8-compat_2.13-1.0.2.jar:/usr/share/java/cp-base-new/kafka-storage-api-7.4.0-ccs.jar:/usr/share/java/cp-base-new/slf4j-reload4j-1.7.36.jar:/usr/share/java/cp-base-new/jmx_prometheus_javaagent-0.18.0.jar:/usr/share/java/cp-base-new/snakeyaml-2.0.jar:/usr/share/java/cp-base-new/minimal-json-0.9.5.jar:/usr/share/java/cp-base-new/jolokia-core-1.7.1.jar:/usr/share/java/cp-base-new/logredactor-1.0.11.jar:/usr/share/java/cp-base-new/kafka-storage-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jackson-module-scala_2.13-2.14.2.jar:/usr/share/java/cp-base-new/kafka-group-coordinator-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jolokia-jvm-1.7.1.jar:/usr/share/java/cp-base-new/kafka-metadata-7.4.0-ccs.jar:/usr/share/java/cp-base-new/argparse4j-0.7.0.jar:/usr/share/java/cp-base-new/lz4-java-1.8.0.jar:/usr/share/java/cp-base-new/kafka_2.13-7.4.0-ccs.jar:/usr/share/java/cp-base-new/jose4j-0.7.9.jar:/usr/share/java/cp-base-new/jackson-core-2.14.2.jar:/usr/share/java/cp-base-new/jopt-simple-5.0.4.jar:/usr/share/java/cp-base-new/disk-usage-agent-7.4.0.jar:/usr/share/java/cp-base-new/metrics-core-4.1.12.1.jar:/usr/share/java/cp-base-new/jackson-databind-2.14.2.jar:/usr/share/java/cp-base-new/scala-logging_2.13-3.9.4.jar:/usr/share/java/cp-base-new/commons-cli-1.4.jar:/usr/share/java/cp-base-new/common-utils-7.4.0.jar:/usr/share/java/cp-base-new/jackson-dataformat-yaml-2.14.2.jar:/usr/share/java/cp-base-new/re2j-1.6.jar:/usr/share/java/cp-base-new/scala-library-2.13.10.jar:/usr/share/java/cp-base-new/gson-2.9.0.jar:/usr/share/java/cp-base-new/json-simple-1.1.1.jar:/usr/share/java/cp-base-new/logredactor-metrics-1.0.11.jar:/usr/share/java/cp-base-new/jackson-dataformat-csv-2.14.2.jar:/usr/share/java/cp-base-new/utility-belt-7.4.0.jar:/usr/share/java/cp-base-new/zookeeper-3.6.3.jar:/usr/share/java/cp-base-new/jackson-datatype-jdk8-2.14.2.jar:/usr/share/java/cp-base-new/scala-reflect-2.13.10.jar:/usr/share/java/cp-base-new/reload4j-1.2.19.jar:/usr/share/java/cp-base-new/audience-annotations-0.5.0.jar:/usr/share/java/cp-base-new/zstd-jni-1.5.2-1.jar:/usr/share/java/cp-base-new/snappy-java-1.1.8.4.jar:/usr/share/java/cp-base-new/jackson-annotations-2.14.2.jar:/usr/share/java/cp-base-new/metrics-core-2.2.0.jar:/usr/share/java/cp-base-new/kafka-clients-7.4.0-ccs.jar:/usr/share/java/cp-base-new/scala-collection-compat_2.13-2.6.0.jar (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.version=5.15.0-142-generic (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.memory.free=1995MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.memory.max=30688MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,642] INFO Client environment:os.memory.total=2012MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,645] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=40000 watcher=io.confluent.admin.utils.ZookeeperConnectionWatcher@646be2c3 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,649] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
upgrade_kafka              | [2025-09-07 13:23:43,656] INFO jute.maxbuffer value is 1048575 Bytes (org.apache.zookeeper.ClientCnxnSocket)
upgrade_kafka              | [2025-09-07 13:23:43,662] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:43,701] INFO Opening socket connection to server zookeeper/172.20.0.6:2181. (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:43,701] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:43,713] INFO Socket connection established, initiating session, client: /172.20.0.8:50792, server: zookeeper/172.20.0.6:2181 (org.apache.zookeeper.ClientCnxn)
upgrade_zookeeper          | [2025-09-07 13:23:43,724] INFO Creating new log file: log.27 (org.apache.zookeeper.server.persistence.FileTxnLog)
upgrade_kafka              | [2025-09-07 13:23:43,743] INFO Session establishment complete on server zookeeper/172.20.0.6:2181, session id = 0x10171cd210f0000, negotiated timeout = 40000 (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:43,859] INFO Session: 0x10171cd210f0000 closed (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:43,859] INFO EventThread shut down for session: 0x10171cd210f0000 (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | Using log4j config /etc/kafka/log4j.properties
upgrade_kafka              | ===> Launching ... 
upgrade_kafka              | ===> Launching kafka ... 
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_producer   | ERROR:__main__:Failed to initialize producer: NoBrokersAvailable
upgrade_weather_producer   | ERROR:__main__:Producer failed: NoBrokersAvailable
upgrade_weather_producer   | INFO:__main__:Cleanup completed
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | ERROR:kafka.conn:Connect attempt to <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]> returned error 111. Disconnecting.
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. KafkaConnectionError: 111 ECONNREFUSED
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: NoBrokersAvailable
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 46, in initialize
upgrade_weather_consumer   |     self.consumer = KafkaConsumer(
upgrade_weather_consumer   |                     ^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/consumer/group.py", line 356, in __init__
upgrade_weather_consumer   |     self._client = KafkaClient(metrics=self._metrics, **self.config)
upgrade_weather_consumer   |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 244, in __init__
upgrade_weather_consumer   |     self.config['api_version'] = self.check_version(timeout=check_timeout)
upgrade_weather_consumer   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/kafka/client_async.py", line 900, in check_version
upgrade_weather_consumer   |     raise Errors.NoBrokersAvailable()
upgrade_weather_consumer   | kafka.errors.NoBrokersAvailable: NoBrokersAvailable
upgrade_kafka              | [2025-09-07 13:23:44,549] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[Kupgrade_weather_producer exited with code 0
upgrade_kafka_ui           | [30m2025-09-07 13:23:44,621[0;39m [39mDEBUG[0;39m [[34mmain[0;39m] [33mc.p.k.u.s.SerdesInitializer[0;39m: Configuring serdes for cluster local
upgrade_kafka              | [2025-09-07 13:23:44,853] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[Kupgrade_weather_consumer exited with code 1
upgrade_kafka              | [2025-09-07 13:23:44,931] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
upgrade_kafka              | [2025-09-07 13:23:44,933] INFO starting (kafka.server.KafkaServer)
upgrade_kafka              | [2025-09-07 13:23:44,933] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
upgrade_kafka              | [2025-09-07 13:23:44,947] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:zookeeper.version=3.6.4--d65253dcf68e9097c6e95a126463fd5fdeb4521c, built on 12/18/2022 18:10 GMT (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:host.name=81126b51c32b (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:java.version=11.0.18 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:java.vendor=Azul Systems, Inc. (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:java.home=/usr/lib/jvm/zulu11-ca (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,951] INFO Client environment:java.class.path=/usr/bin/../share/java/kafka/hk2-api-2.6.1.jar:/usr/bin/../share/java/kafka/kafka-raft-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.13.4.jar:/usr/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/usr/bin/../share/java/kafka/jersey-client-2.34.jar:/usr/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/usr/bin/../share/java/kafka/jersey-hk2-2.34.jar:/usr/bin/../share/java/kafka/jackson-databind-2.13.4.2.jar:/usr/bin/../share/java/kafka/connect-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-runtime-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/reflections-0.9.12.jar:/usr/bin/../share/java/kafka/kafka-server-common-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/paranamer-2.8.jar:/usr/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/usr/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/usr/bin/../share/java/kafka/kafka-storage-api-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/usr/bin/../share/java/kafka/jetty-client-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jersey-common-2.34.jar:/usr/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/usr/bin/../share/java/kafka/kafka-streams-examples-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/connect-mirror-client-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/usr/bin/../share/java/kafka/jackson-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-scala_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-json-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jackson-dataformat-csv-2.13.4.jar:/usr/bin/../share/java/kafka/netty-handler-4.1.86.Final.jar:/usr/bin/../share/java/kafka/kafka-storage-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/usr/bin/../share/java/kafka/kafka-group-coordinator-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/maven-artifact-3.8.4.jar:/usr/bin/../share/java/kafka/kafka.jar:/usr/bin/../share/java/kafka/jetty-util-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-metadata-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/argparse4j-0.7.0.jar:/usr/bin/../share/java/kafka/kafka-tools-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-transforms-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/usr/bin/../share/java/kafka/lz4-java-1.8.0.jar:/usr/bin/../share/java/kafka/kafka-shell-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/kafka_2.13-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/netty-transport-native-epoll-4.1.86.Final.jar:/usr/bin/../share/java/kafka/zookeeper-3.6.4.jar:/usr/bin/../share/java/kafka/jose4j-0.7.9.jar:/usr/bin/../share/java/kafka/jetty-security-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/swagger-annotations-2.2.0.jar:/usr/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/usr/bin/../share/java/kafka/jackson-core-2.13.4.jar:/usr/bin/../share/java/kafka/connect-basic-auth-extension-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/javassist-3.27.0-GA.jar:/usr/bin/../share/java/kafka/zookeeper-jute-3.6.4.jar:/usr/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/usr/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/usr/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/usr/bin/../share/java/kafka/commons-cli-1.4.jar:/usr/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/usr/bin/../share/java/kafka/jackson-module-scala_2.13-2.13.4.jar:/usr/bin/../share/java/kafka/jetty-continuation-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-streams-test-utils-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/rocksdbjni-7.1.2.jar:/usr/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.13.4.jar:/usr/bin/../share/java/kafka/activation-1.1.1.jar:/usr/bin/../share/java/kafka/jackson-datatype-jdk8-2.13.4.jar:/usr/bin/../share/java/kafka/audience-annotations-0.13.0.jar:/usr/bin/../share/java/kafka/scala-library-2.13.10.jar:/usr/bin/../share/java/kafka/jetty-server-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-transport-4.1.86.Final.jar:/usr/bin/../share/java/kafka/netty-buffer-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jackson-jaxrs-base-2.13.4.jar:/usr/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/usr/bin/../share/java/kafka/trogdor-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/usr/bin/../share/java/kafka/netty-resolver-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jetty-servlets-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/jetty-http-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/usr/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/usr/bin/../share/java/kafka/jline-3.21.0.jar:/usr/bin/../share/java/kafka/kafka-log4j-appender-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/connect-mirror-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/usr/bin/../share/java/kafka/netty-common-4.1.86.Final.jar:/usr/bin/../share/java/kafka/jetty-io-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/usr/bin/../share/java/kafka/reload4j-1.2.19.jar:/usr/bin/../share/java/kafka/zstd-jni-1.5.2-1.jar:/usr/bin/../share/java/kafka/snappy-java-1.1.8.4.jar:/usr/bin/../share/java/kafka/metrics-core-2.2.0.jar:/usr/bin/../share/java/kafka/jetty-servlet-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/kafka-clients-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/usr/bin/../share/java/kafka/jersey-server-2.34.jar:/usr/bin/../share/java/kafka/kafka-streams-7.4.0-ccs.jar:/usr/bin/../share/java/kafka/plexus-utils-3.3.0.jar:/usr/bin/../share/java/kafka/jersey-container-servlet-core-2.34.jar:/usr/bin/../share/java/kafka/jetty-util-ajax-9.4.48.v20220622.jar:/usr/bin/../share/java/kafka/netty-codec-4.1.86.Final.jar:/usr/bin/../share/java/kafka/scala-collection-compat_2.13-2.6.0.jar:/usr/bin/../share/java/confluent-telemetry/* (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.version=5.15.0-142-generic (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:user.name=appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:user.home=/home/appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:user.dir=/home/appuser (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.memory.free=1008MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,952] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,954] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@74c79fa2 (org.apache.zookeeper.ZooKeeper)
upgrade_kafka              | [2025-09-07 13:23:44,958] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
upgrade_kafka              | [2025-09-07 13:23:44,963] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:44,965] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
upgrade_kafka              | [2025-09-07 13:23:44,967] INFO Opening socket connection to server zookeeper/172.20.0.6:2181. (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:44,973] INFO Socket connection established, initiating session, client: /172.20.0.8:50802, server: zookeeper/172.20.0.6:2181 (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:44,980] INFO Session establishment complete on server zookeeper/172.20.0.6:2181, session id = 0x10171cd210f0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
upgrade_kafka              | [2025-09-07 13:23:44,983] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
upgrade_kafka              | [2025-09-07 13:23:45,203] INFO Cluster ID = Hp5enf1fRZago8m16lYMBQ (kafka.server.KafkaServer)
upgrade_kafka              | [2025-09-07 13:23:45,249] INFO KafkaConfig values: 
upgrade_kafka              | 	advertised.listeners = PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
upgrade_kafka              | 	alter.config.policy.class.name = null
upgrade_kafka              | 	alter.log.dirs.replication.quota.window.num = 11
upgrade_kafka              | 	alter.log.dirs.replication.quota.window.size.seconds = 1
upgrade_kafka              | 	authorizer.class.name = 
upgrade_kafka              | 	auto.create.topics.enable = true
upgrade_kafka              | 	auto.include.jmx.reporter = true
upgrade_kafka              | 	auto.leader.rebalance.enable = true
upgrade_kafka              | 	background.threads = 10
upgrade_kafka              | 	broker.heartbeat.interval.ms = 2000
upgrade_kafka              | 	broker.id = 1
upgrade_kafka              | 	broker.id.generation.enable = true
upgrade_kafka              | 	broker.rack = null
upgrade_kafka              | 	broker.session.timeout.ms = 9000
upgrade_kafka              | 	client.quota.callback.class = null
upgrade_kafka              | 	compression.type = producer
upgrade_kafka              | 	connection.failed.authentication.delay.ms = 100
upgrade_kafka              | 	connections.max.idle.ms = 600000
upgrade_kafka              | 	connections.max.reauth.ms = 0
upgrade_kafka              | 	control.plane.listener.name = null
upgrade_kafka              | 	controlled.shutdown.enable = true
upgrade_kafka              | 	controlled.shutdown.max.retries = 3
upgrade_kafka              | 	controlled.shutdown.retry.backoff.ms = 5000
upgrade_kafka              | 	controller.listener.names = null
upgrade_kafka              | 	controller.quorum.append.linger.ms = 25
upgrade_kafka              | 	controller.quorum.election.backoff.max.ms = 1000
upgrade_kafka              | 	controller.quorum.election.timeout.ms = 1000
upgrade_kafka              | 	controller.quorum.fetch.timeout.ms = 2000
upgrade_kafka              | 	controller.quorum.request.timeout.ms = 2000
upgrade_kafka              | 	controller.quorum.retry.backoff.ms = 20
upgrade_kafka              | 	controller.quorum.voters = []
upgrade_kafka              | 	controller.quota.window.num = 11
upgrade_kafka              | 	controller.quota.window.size.seconds = 1
upgrade_kafka              | 	controller.socket.timeout.ms = 30000
upgrade_kafka              | 	create.topic.policy.class.name = null
upgrade_kafka              | 	default.replication.factor = 1
upgrade_kafka              | 	delegation.token.expiry.check.interval.ms = 3600000
upgrade_kafka              | 	delegation.token.expiry.time.ms = 86400000
upgrade_kafka              | 	delegation.token.master.key = null
upgrade_kafka              | 	delegation.token.max.lifetime.ms = 604800000
upgrade_kafka              | 	delegation.token.secret.key = null
upgrade_kafka              | 	delete.records.purgatory.purge.interval.requests = 1
upgrade_kafka              | 	delete.topic.enable = true
upgrade_kafka              | 	early.start.listeners = null
upgrade_kafka              | 	fetch.max.bytes = 57671680
upgrade_kafka              | 	fetch.purgatory.purge.interval.requests = 1000
upgrade_kafka              | 	group.initial.rebalance.delay.ms = 3000
upgrade_kafka              | 	group.max.session.timeout.ms = 1800000
upgrade_kafka              | 	group.max.size = 2147483647
upgrade_kafka              | 	group.min.session.timeout.ms = 6000
upgrade_kafka              | 	initial.broker.registration.timeout.ms = 60000
upgrade_kafka              | 	inter.broker.listener.name = null
upgrade_kafka              | 	inter.broker.protocol.version = 3.4-IV0
upgrade_kafka              | 	kafka.metrics.polling.interval.secs = 10
upgrade_kafka              | 	kafka.metrics.reporters = []
upgrade_kafka              | 	leader.imbalance.check.interval.seconds = 300
upgrade_kafka              | 	leader.imbalance.per.broker.percentage = 10
upgrade_kafka              | 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
upgrade_kafka              | 	listeners = PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
upgrade_kafka              | 	log.cleaner.backoff.ms = 15000
upgrade_kafka              | 	log.cleaner.dedupe.buffer.size = 134217728
upgrade_kafka              | 	log.cleaner.delete.retention.ms = 86400000
upgrade_kafka              | 	log.cleaner.enable = true
upgrade_kafka              | 	log.cleaner.io.buffer.load.factor = 0.9
upgrade_kafka              | 	log.cleaner.io.buffer.size = 524288
upgrade_kafka              | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
upgrade_kafka              | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
upgrade_kafka              | 	log.cleaner.min.cleanable.ratio = 0.5
upgrade_kafka              | 	log.cleaner.min.compaction.lag.ms = 0
upgrade_kafka              | 	log.cleaner.threads = 1
upgrade_kafka              | 	log.cleanup.policy = [delete]
upgrade_kafka              | 	log.dir = /tmp/kafka-logs
upgrade_kafka              | 	log.dirs = /var/lib/kafka/data
upgrade_kafka              | 	log.flush.interval.messages = 9223372036854775807
upgrade_kafka              | 	log.flush.interval.ms = null
upgrade_kafka              | 	log.flush.offset.checkpoint.interval.ms = 60000
upgrade_kafka              | 	log.flush.scheduler.interval.ms = 9223372036854775807
upgrade_kafka              | 	log.flush.start.offset.checkpoint.interval.ms = 60000
upgrade_kafka              | 	log.index.interval.bytes = 4096
upgrade_kafka              | 	log.index.size.max.bytes = 10485760
upgrade_kafka              | 	log.message.downconversion.enable = true
upgrade_kafka              | 	log.message.format.version = 3.0-IV1
upgrade_kafka              | 	log.message.timestamp.difference.max.ms = 9223372036854775807
upgrade_kafka              | 	log.message.timestamp.type = CreateTime
upgrade_kafka              | 	log.preallocate = false
upgrade_kafka              | 	log.retention.bytes = -1
upgrade_kafka              | 	log.retention.check.interval.ms = 300000
upgrade_kafka              | 	log.retention.hours = 168
upgrade_kafka              | 	log.retention.minutes = null
upgrade_kafka              | 	log.retention.ms = null
upgrade_kafka              | 	log.roll.hours = 168
upgrade_kafka              | 	log.roll.jitter.hours = 0
upgrade_kafka              | 	log.roll.jitter.ms = null
upgrade_kafka              | 	log.roll.ms = null
upgrade_kafka              | 	log.segment.bytes = 1073741824
upgrade_kafka              | 	log.segment.delete.delay.ms = 60000
upgrade_kafka              | 	max.connection.creation.rate = 2147483647
upgrade_kafka              | 	max.connections = 2147483647
upgrade_kafka              | 	max.connections.per.ip = 2147483647
upgrade_kafka              | 	max.connections.per.ip.overrides = 
upgrade_kafka              | 	max.incremental.fetch.session.cache.slots = 1000
upgrade_kafka              | 	message.max.bytes = 1048588
upgrade_kafka              | 	metadata.log.dir = null
upgrade_kafka              | 	metadata.log.max.record.bytes.between.snapshots = 20971520
upgrade_kafka              | 	metadata.log.max.snapshot.interval.ms = 3600000
upgrade_kafka              | 	metadata.log.segment.bytes = 1073741824
upgrade_kafka              | 	metadata.log.segment.min.bytes = 8388608
upgrade_kafka              | 	metadata.log.segment.ms = 604800000
upgrade_kafka              | 	metadata.max.idle.interval.ms = 500
upgrade_kafka              | 	metadata.max.retention.bytes = 104857600
upgrade_kafka              | 	metadata.max.retention.ms = 604800000
upgrade_kafka              | 	metric.reporters = []
upgrade_kafka              | 	metrics.num.samples = 2
upgrade_kafka              | 	metrics.recording.level = INFO
upgrade_kafka              | 	metrics.sample.window.ms = 30000
upgrade_kafka              | 	min.insync.replicas = 1
upgrade_kafka              | 	node.id = 1
upgrade_kafka              | 	num.io.threads = 8
upgrade_kafka              | 	num.network.threads = 3
upgrade_kafka              | 	num.partitions = 1
upgrade_kafka              | 	num.recovery.threads.per.data.dir = 1
upgrade_kafka              | 	num.replica.alter.log.dirs.threads = null
upgrade_kafka              | 	num.replica.fetchers = 1
upgrade_kafka              | 	offset.metadata.max.bytes = 4096
upgrade_kafka              | 	offsets.commit.required.acks = -1
upgrade_kafka              | 	offsets.commit.timeout.ms = 5000
upgrade_kafka              | 	offsets.load.buffer.size = 5242880
upgrade_kafka              | 	offsets.retention.check.interval.ms = 600000
upgrade_kafka              | 	offsets.retention.minutes = 10080
upgrade_kafka              | 	offsets.topic.compression.codec = 0
upgrade_kafka              | 	offsets.topic.num.partitions = 50
upgrade_kafka              | 	offsets.topic.replication.factor = 1
upgrade_kafka              | 	offsets.topic.segment.bytes = 104857600
upgrade_kafka              | 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
upgrade_kafka              | 	password.encoder.iterations = 4096
upgrade_kafka              | 	password.encoder.key.length = 128
upgrade_kafka              | 	password.encoder.keyfactory.algorithm = null
upgrade_kafka              | 	password.encoder.old.secret = null
upgrade_kafka              | 	password.encoder.secret = null
upgrade_kafka              | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
upgrade_kafka              | 	process.roles = []
upgrade_kafka              | 	producer.id.expiration.check.interval.ms = 600000
upgrade_kafka              | 	producer.id.expiration.ms = 86400000
upgrade_kafka              | 	producer.purgatory.purge.interval.requests = 1000
upgrade_kafka              | 	queued.max.request.bytes = -1
upgrade_kafka              | 	queued.max.requests = 500
upgrade_kafka              | 	quota.window.num = 11
upgrade_kafka              | 	quota.window.size.seconds = 1
upgrade_kafka              | 	remote.log.index.file.cache.total.size.bytes = 1073741824
upgrade_kafka              | 	remote.log.manager.task.interval.ms = 30000
upgrade_kafka              | 	remote.log.manager.task.retry.backoff.max.ms = 30000
upgrade_kafka              | 	remote.log.manager.task.retry.backoff.ms = 500
upgrade_kafka              | 	remote.log.manager.task.retry.jitter = 0.2
upgrade_kafka              | 	remote.log.manager.thread.pool.size = 10
upgrade_kafka              | 	remote.log.metadata.manager.class.name = null
upgrade_kafka              | 	remote.log.metadata.manager.class.path = null
upgrade_kafka              | 	remote.log.metadata.manager.impl.prefix = null
upgrade_kafka              | 	remote.log.metadata.manager.listener.name = null
upgrade_kafka              | 	remote.log.reader.max.pending.tasks = 100
upgrade_kafka              | 	remote.log.reader.threads = 10
upgrade_kafka              | 	remote.log.storage.manager.class.name = null
upgrade_kafka              | 	remote.log.storage.manager.class.path = null
upgrade_kafka              | 	remote.log.storage.manager.impl.prefix = null
upgrade_kafka              | 	remote.log.storage.system.enable = false
upgrade_kafka              | 	replica.fetch.backoff.ms = 1000
upgrade_kafka              | 	replica.fetch.max.bytes = 1048576
upgrade_kafka              | 	replica.fetch.min.bytes = 1
upgrade_kafka              | 	replica.fetch.response.max.bytes = 10485760
upgrade_kafka              | 	replica.fetch.wait.max.ms = 500
upgrade_kafka              | 	replica.high.watermark.checkpoint.interval.ms = 5000
upgrade_kafka              | 	replica.lag.time.max.ms = 30000
upgrade_kafka              | 	replica.selector.class = null
upgrade_kafka              | 	replica.socket.receive.buffer.bytes = 65536
upgrade_kafka              | 	replica.socket.timeout.ms = 30000
upgrade_kafka              | 	replication.quota.window.num = 11
upgrade_kafka              | 	replication.quota.window.size.seconds = 1
upgrade_kafka              | 	request.timeout.ms = 30000
upgrade_kafka              | 	reserved.broker.max.id = 1000
upgrade_kafka              | 	sasl.client.callback.handler.class = null
upgrade_kafka              | 	sasl.enabled.mechanisms = [GSSAPI]
upgrade_kafka              | 	sasl.jaas.config = null
upgrade_kafka              | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
upgrade_kafka              | 	sasl.kerberos.min.time.before.relogin = 60000
upgrade_kafka              | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
upgrade_kafka              | 	sasl.kerberos.service.name = null
upgrade_kafka              | 	sasl.kerberos.ticket.renew.jitter = 0.05
upgrade_kafka              | 	sasl.kerberos.ticket.renew.window.factor = 0.8
upgrade_kafka              | 	sasl.login.callback.handler.class = null
upgrade_kafka              | 	sasl.login.class = null
upgrade_kafka              | 	sasl.login.connect.timeout.ms = null
upgrade_kafka              | 	sasl.login.read.timeout.ms = null
upgrade_kafka              | 	sasl.login.refresh.buffer.seconds = 300
upgrade_kafka              | 	sasl.login.refresh.min.period.seconds = 60
upgrade_kafka              | 	sasl.login.refresh.window.factor = 0.8
upgrade_kafka              | 	sasl.login.refresh.window.jitter = 0.05
upgrade_kafka              | 	sasl.login.retry.backoff.max.ms = 10000
upgrade_kafka              | 	sasl.login.retry.backoff.ms = 100
upgrade_kafka              | 	sasl.mechanism.controller.protocol = GSSAPI
upgrade_kafka              | 	sasl.mechanism.inter.broker.protocol = GSSAPI
upgrade_kafka              | 	sasl.oauthbearer.clock.skew.seconds = 30
upgrade_kafka              | 	sasl.oauthbearer.expected.audience = null
upgrade_kafka              | 	sasl.oauthbearer.expected.issuer = null
upgrade_kafka              | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
upgrade_kafka              | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
upgrade_kafka              | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
upgrade_kafka              | 	sasl.oauthbearer.jwks.endpoint.url = null
upgrade_kafka              | 	sasl.oauthbearer.scope.claim.name = scope
upgrade_kafka              | 	sasl.oauthbearer.sub.claim.name = sub
upgrade_kafka              | 	sasl.oauthbearer.token.endpoint.url = null
upgrade_kafka              | 	sasl.server.callback.handler.class = null
upgrade_kafka              | 	sasl.server.max.receive.size = 524288
upgrade_kafka              | 	security.inter.broker.protocol = PLAINTEXT
upgrade_kafka              | 	security.providers = null
upgrade_kafka              | 	socket.connection.setup.timeout.max.ms = 30000
upgrade_kafka              | 	socket.connection.setup.timeout.ms = 10000
upgrade_kafka              | 	socket.listen.backlog.size = 50
upgrade_kafka              | 	socket.receive.buffer.bytes = 102400
upgrade_kafka              | 	socket.request.max.bytes = 104857600
upgrade_kafka              | 	socket.send.buffer.bytes = 102400
upgrade_kafka              | 	ssl.cipher.suites = []
upgrade_kafka              | 	ssl.client.auth = none
upgrade_kafka              | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
upgrade_kafka              | 	ssl.endpoint.identification.algorithm = https
upgrade_kafka              | 	ssl.engine.factory.class = null
upgrade_kafka              | 	ssl.key.password = null
upgrade_kafka              | 	ssl.keymanager.algorithm = SunX509
upgrade_kafka              | 	ssl.keystore.certificate.chain = null
upgrade_kafka              | 	ssl.keystore.key = null
upgrade_kafka              | 	ssl.keystore.location = null
upgrade_kafka              | 	ssl.keystore.password = null
upgrade_kafka              | 	ssl.keystore.type = JKS
upgrade_kafka              | 	ssl.principal.mapping.rules = DEFAULT
upgrade_kafka              | 	ssl.protocol = TLSv1.3
upgrade_kafka              | 	ssl.provider = null
upgrade_kafka              | 	ssl.secure.random.implementation = null
upgrade_kafka              | 	ssl.trustmanager.algorithm = PKIX
upgrade_kafka              | 	ssl.truststore.certificates = null
upgrade_kafka              | 	ssl.truststore.location = null
upgrade_kafka              | 	ssl.truststore.password = null
upgrade_kafka              | 	ssl.truststore.type = JKS
upgrade_kafka              | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
upgrade_kafka              | 	transaction.max.timeout.ms = 900000
upgrade_kafka              | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
upgrade_kafka              | 	transaction.state.log.load.buffer.size = 5242880
upgrade_kafka              | 	transaction.state.log.min.isr = 2
upgrade_kafka              | 	transaction.state.log.num.partitions = 50
upgrade_kafka              | 	transaction.state.log.replication.factor = 3
upgrade_kafka              | 	transaction.state.log.segment.bytes = 104857600
upgrade_kafka              | 	transactional.id.expiration.ms = 604800000
upgrade_kafka              | 	unclean.leader.election.enable = false
upgrade_kafka              | 	zookeeper.clientCnxnSocket = null
upgrade_kafka              | 	zookeeper.connect = zookeeper:2181
upgrade_kafka              | 	zookeeper.connection.timeout.ms = null
upgrade_kafka              | 	zookeeper.max.in.flight.requests = 10
upgrade_kafka              | 	zookeeper.metadata.migration.enable = false
upgrade_kafka              | 	zookeeper.session.timeout.ms = 18000
upgrade_kafka              | 	zookeeper.set.acl = false
upgrade_kafka              | 	zookeeper.ssl.cipher.suites = null
upgrade_kafka              | 	zookeeper.ssl.client.enable = false
upgrade_kafka              | 	zookeeper.ssl.crl.enable = false
upgrade_kafka              | 	zookeeper.ssl.enabled.protocols = null
upgrade_kafka              | 	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
upgrade_kafka              | 	zookeeper.ssl.keystore.location = null
upgrade_kafka              | 	zookeeper.ssl.keystore.password = null
upgrade_kafka              | 	zookeeper.ssl.keystore.type = null
upgrade_kafka              | 	zookeeper.ssl.ocsp.enable = false
upgrade_kafka              | 	zookeeper.ssl.protocol = TLSv1.2
upgrade_kafka              | 	zookeeper.ssl.truststore.location = null
upgrade_kafka              | 	zookeeper.ssl.truststore.password = null
upgrade_kafka              | 	zookeeper.ssl.truststore.type = null
upgrade_kafka              |  (kafka.server.KafkaConfig)
upgrade_kafka              | [2025-09-07 13:23:45,283] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
upgrade_kafka              | [2025-09-07 13:23:45,283] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
upgrade_kafka              | [2025-09-07 13:23:45,284] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
upgrade_kafka              | [2025-09-07 13:23:45,287] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
upgrade_kafka              | [2025-09-07 13:23:45,339] INFO Loading logs from log dirs ArraySeq(/var/lib/kafka/data) (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,342] INFO Skipping recovery for all logs in /var/lib/kafka/data since clean shutdown file was found (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,439] INFO Deleted producer state snapshot /var/lib/kafka/data/weather-data-0/00000000000000000005.snapshot (kafka.log.SnapshotFile)
upgrade_kafka              | [2025-09-07 13:23:45,444] INFO [LogLoader partition=weather-data-0, dir=/var/lib/kafka/data] Loading producer state till offset 10 with message format version 2 (kafka.log.UnifiedLog$)
upgrade_kafka              | [2025-09-07 13:23:45,445] INFO [LogLoader partition=weather-data-0, dir=/var/lib/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 10 (kafka.log.UnifiedLog$)
upgrade_kafka              | [2025-09-07 13:23:45,446] INFO [ProducerStateManager partition=weather-data-0] Loading producer state from snapshot file 'SnapshotFile(/var/lib/kafka/data/weather-data-0/00000000000000000010.snapshot,10)' (kafka.log.ProducerStateManager)
upgrade_kafka              | [2025-09-07 13:23:45,454] INFO [LogLoader partition=weather-data-0, dir=/var/lib/kafka/data] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 10 (kafka.log.UnifiedLog$)
upgrade_kafka_ui           | [30m2025-09-07 13:23:45,460[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.s.r.ReactiveUserDetailsServiceAutoConfiguration[0;39m: 
upgrade_kafka_ui           | 
upgrade_kafka_ui           | Using generated security password: 737854ce-1bb0-4233-b825-e103010ca346
upgrade_kafka_ui           | 
upgrade_kafka              | [2025-09-07 13:23:45,474] INFO Completed load of Log(dir=/var/lib/kafka/data/weather-data-0, topicId=ZRXHQvC3QtS5sV0GGqAJ2Q, topic=weather-data, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=10) with 1 segments in 119ms (1/1 completed in /var/lib/kafka/data) (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,479] INFO Loaded 1 logs in 140ms. (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,480] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,481] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
upgrade_kafka              | [2025-09-07 13:23:45,508] INFO Starting the log cleaner (kafka.log.LogCleaner)
upgrade_kafka              | [2025-09-07 13:23:45,595] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner)
upgrade_kafka              | [2025-09-07 13:23:45,609] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
upgrade_kafka              | [2025-09-07 13:23:45,630] INFO [MetadataCache brokerId=1] Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Map(), epoch=0). (kafka.server.metadata.ZkMetadataCache)
upgrade_kafka              | [2025-09-07 13:23:45,657] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
upgrade_kafka_ui           | [30m2025-09-07 13:23:45,660[0;39m [31mWARN [0;39m [[34mmain[0;39m] [33mc.p.k.u.c.a.DisabledAuthSecurityConfig[0;39m: Authentication is disabled. Access will be unrestricted.
upgrade_kafka_ui           | [30m2025-09-07 13:23:45,916[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.a.e.w.EndpointLinksResolver[0;39m: Exposing 3 endpoint(s) beneath base path '/actuator'
upgrade_kafka              | [2025-09-07 13:23:45,996] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
upgrade_kafka              | [2025-09-07 13:23:46,001] INFO Awaiting socket connections on 0.0.0.0:29092. (kafka.network.DataPlaneAcceptor)
upgrade_kafka              | [2025-09-07 13:23:46,025] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
upgrade_kafka              | [2025-09-07 13:23:46,026] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
upgrade_kafka              | [2025-09-07 13:23:46,026] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
upgrade_kafka              | [2025-09-07 13:23:46,029] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT_HOST) (kafka.network.SocketServer)
upgrade_kafka              | [2025-09-07 13:23:46,035] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Starting (kafka.server.BrokerToControllerRequestThread)
upgrade_kafka              | [2025-09-07 13:23:46,057] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,060] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,061] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,066] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,082] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
upgrade_kafka              | [2025-09-07 13:23:46,133] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
upgrade_kafka              | [2025-09-07 13:23:46,161] INFO Stat of the created znode at /brokers/ids/1 is: 56,56,1757251426147,1757251426147,1,0,0,72464194851504129,259,0,56
upgrade_kafka              |  (kafka.zk.KafkaZkClient)
upgrade_kafka              | [2025-09-07 13:23:46,162] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092, czxid (broker epoch): 56 (kafka.zk.KafkaZkClient)
upgrade_kafka              | [2025-09-07 13:23:46,219] INFO [ControllerEventThread controllerId=1] Starting (kafka.controller.ControllerEventManager$ControllerEventThread)
upgrade_kafka              | [2025-09-07 13:23:46,227] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,231] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,232] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,244] INFO [Controller id=1] 1 successfully elected as the controller. Epoch incremented to 2 and epoch zk version is now 2 (kafka.controller.KafkaController)
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_kafka              | [2025-09-07 13:23:46,247] INFO [Controller id=1] Registering handlers (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,248] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_kafka              | [2025-09-07 13:23:46,254] INFO [Controller id=1] Deleting log dir event notifications (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,255] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
upgrade_kafka              | [2025-09-07 13:23:46,261] INFO [Controller id=1] Deleting isr change notifications (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,263] INFO [Controller id=1] Initializing controller context (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,270] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
upgrade_kafka              | [2025-09-07 13:23:46,276] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
upgrade_kafka              | [2025-09-07 13:23:46,276] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
upgrade_kafka              | [2025-09-07 13:23:46,280] INFO [Controller id=1] Initialized broker epochs cache: HashMap(1 -> 56) (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,292] DEBUG [Controller id=1] Register BrokerModifications handler for Set(1) (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,302] DEBUG [Channel manager on controller 1]: Controller 1 trying to connect to broker 1 (kafka.controller.ControllerChannelManager)
upgrade_kafka              | [2025-09-07 13:23:46,346] INFO [RequestSendThread controllerId=1] Starting (kafka.controller.RequestSendThread)
upgrade_kafka              | [2025-09-07 13:23:46,347] INFO [Controller id=1] Currently active brokers in the cluster: Set(1) (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,348] INFO [Controller id=1] Currently shutting brokers in the cluster: HashSet() (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,348] INFO [Controller id=1] Current list of topics in the cluster: HashSet(weather-data) (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,348] INFO [Controller id=1] Fetching topic deletions in progress (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,351] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
upgrade_kafka              | [2025-09-07 13:23:46,352] INFO [Controller id=1] List of topics to be deleted:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,352] INFO [Controller id=1] List of topics ineligible for deletion:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,353] INFO [Controller id=1] Initializing topic deletion manager (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,353] INFO [Topic Deletion Manager 1] Initializing manager with initial deletions: Set(), initial ineligible deletions: HashSet() (kafka.controller.TopicDeletionManager)
upgrade_kafka              | [2025-09-07 13:23:46,354] INFO [Controller id=1] Sending update metadata request (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,356] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 0 partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,362] INFO [ReplicaStateMachine controllerId=1] Initializing replica state (kafka.controller.ZkReplicaStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,365] INFO [ReplicaStateMachine controllerId=1] Triggering online replica state changes (kafka.controller.ZkReplicaStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,369] INFO [RequestSendThread controllerId=1] Controller 1 connected to kafka:29092 (id: 1 rack: null) for sending state change requests (kafka.controller.RequestSendThread)
upgrade_weather_producer   | INFO:__main__:Starting Weather Producer for UPGRADE project
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_kafka              | [2025-09-07 13:23:46,375] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
upgrade_kafka              | [2025-09-07 13:23:46,377] TRACE [Controller id=1 epoch=2] Changed state of replica 1 for partition weather-data-0 from OnlineReplica to OnlineReplica (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,380] TRACE [Controller id=1 epoch=2] Sending become-leader LeaderAndIsr request LeaderAndIsrPartitionState(topicName='weather-data', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) to broker 1 for partition weather-data-0 (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,381] INFO [Controller id=1 epoch=2] Sending LeaderAndIsr request to broker 1 with 1 become-leader and 0 become-follower partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,382] INFO [Controller id=1 epoch=2] Sending UpdateMetadata request to brokers HashSet(1) for 1 partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,383] INFO [ReplicaStateMachine controllerId=1] Triggering offline replica state changes (kafka.controller.ZkReplicaStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,383] DEBUG [ReplicaStateMachine controllerId=1] Started replica state machine with initial state -> HashMap([Topic=weather-data,Partition=0,Replica=1] -> OnlineReplica) (kafka.controller.ZkReplicaStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,383] INFO [PartitionStateMachine controllerId=1] Initializing partition state (kafka.controller.ZkPartitionStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,385] INFO [PartitionStateMachine controllerId=1] Triggering online partition state changes (kafka.controller.ZkPartitionStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,387] DEBUG [PartitionStateMachine controllerId=1] Started partition state machine with initial state -> HashMap(weather-data-0 -> OnlinePartition) (kafka.controller.ZkPartitionStateMachine)
upgrade_kafka              | [2025-09-07 13:23:46,387] INFO [Controller id=1] Ready to serve as the new controller with epoch 2 (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,393] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
upgrade_kafka              | [2025-09-07 13:23:46,393] INFO [Controller id=1] Partitions undergoing preferred replica election:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,393] INFO [Controller id=1] Partitions that completed preferred replica election:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,394] INFO [Controller id=1] Skipping preferred replica election for partitions due to topic deletion:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,394] INFO [Controller id=1] Resuming preferred replica election for partitions:  (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,395] INFO [Controller id=1] Starting replica leader election (PREFERRED) for partitions  triggered by ZkTriggered (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,403] INFO Kafka version: 7.4.0-ccs (org.apache.kafka.common.utils.AppInfoParser)
upgrade_kafka              | [2025-09-07 13:23:46,403] INFO Kafka commitId: 30969fa33c185e880b9e02044761dfaac013151d (org.apache.kafka.common.utils.AppInfoParser)
upgrade_kafka              | [2025-09-07 13:23:46,403] INFO Kafka startTimeMs: 1757251426397 (org.apache.kafka.common.utils.AppInfoParser)
upgrade_kafka              | [2025-09-07 13:23:46,404] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
upgrade_kafka              | [2025-09-07 13:23:46,413] INFO [Controller id=1] Starting the controller scheduler (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:46,444] INFO [BrokerToControllerChannelManager broker=1 name=alterPartition]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
upgrade_kafka              | [2025-09-07 13:23:46,450] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 0 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,459] INFO [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 for 1 partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,460] TRACE [Broker id=1] Received LeaderAndIsr request LeaderAndIsrPartitionState(topicName='weather-data', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], partitionEpoch=0, replicas=[1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) correlation id 1 from controller 1 epoch 2 (state.change.logger)
upgrade_weather_consumer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_consumer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_consumer   | INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('weather-data',)
upgrade_weather_producer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_producer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_producer   | INFO:__main__:Producer initialized successfully
upgrade_weather_producer   | INFO:__main__:Running initial weather data collection...
upgrade_weather_producer   | INFO:__main__:Starting weather collection for 5 cities
upgrade_postgres           | 2025-09-07 13:23:46.478 UTC [33] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:23:46.478 UTC [33] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 58, in initialize
upgrade_weather_consumer   |     self.postgres_conn = psycopg2.connect(self.postgres_url)
upgrade_weather_consumer   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/psycopg2/__init__.py", line 122, in connect
upgrade_weather_consumer   |     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
upgrade_weather_consumer   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   | psycopg2.OperationalError: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_kafka              | [2025-09-07 13:23:46,480] TRACE [Broker id=1] Handling LeaderAndIsr request correlationId 1 from controller 1 epoch 2 starting the become-leader transition for partition weather-data-0 (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,481] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(weather-data-0) (kafka.server.ReplicaFetcherManager)
upgrade_kafka              | [2025-09-07 13:23:46,482] INFO [Broker id=1] Stopped fetchers as part of LeaderAndIsr request correlationId 1 from controller 1 epoch 2 as part of the become-leader transition for 1 partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,488] INFO [Partition weather-data-0 broker=1] Log loaded for partition weather-data-0 with initial high watermark 10 (kafka.cluster.Partition)
upgrade_kafka              | [2025-09-07 13:23:46,490] INFO [Broker id=1] Leader weather-data-0 with topic id Some(ZRXHQvC3QtS5sV0GGqAJ2Q) starts at leader epoch 0 from offset 10 with partition epoch 0, high watermark 10, ISR [1], adding replicas [] and removing replicas []. Previous leader epoch was -1. (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,493] TRACE [Broker id=1] Completed LeaderAndIsr request correlationId 1 from controller 1 epoch 2 for the become-leader transition for partition weather-data-0 (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,497] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use node kafka:29092 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
upgrade_kafka              | [2025-09-07 13:23:46,499] INFO [Broker id=1] Finished LeaderAndIsr request in 41ms correlationId 1 from controller 1 for 1 partitions (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,503] TRACE [Controller id=1 epoch=2] Received response LeaderAndIsrResponseData(errorCode=0, partitionErrors=[], topics=[LeaderAndIsrTopicError(topicId=ZRXHQvC3QtS5sV0GGqAJ2Q, partitionErrors=[LeaderAndIsrPartitionError(topicName='', partitionIndex=0, errorCode=0)])]) for request LEADER_AND_ISR with correlation id 1 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,507] TRACE [Broker id=1] Cached leader info UpdateMetadataPartitionState(topicName='weather-data', partitionIndex=0, controllerEpoch=1, leader=1, leaderEpoch=0, isr=[1], zkVersion=0, replicas=[1], offlineReplicas=[]) for partition weather-data-0 in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,508] INFO [Broker id=1] Add 1 partitions and deleted 0 partitions from metadata cache in response to UpdateMetadata request sent by controller 1 epoch 2 with correlation id 2 (state.change.logger)
upgrade_kafka              | [2025-09-07 13:23:46,508] TRACE [Controller id=1 epoch=2] Received response UpdateMetadataResponseData(errorCode=0) for request UPDATE_METADATA with correlation id 2 sent to broker kafka:29092 (id: 1 rack: null) (state.change.logger)
upgrade_weather_producer   | INFO:__main__:Successfully collected weather data for Suceava
upgrade_kafka_ui           | [30m2025-09-07 13:23:46,584[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mo.s.b.w.e.n.NettyWebServer[0;39m: Netty started on port 8080
upgrade_kafka_ui           | [30m2025-09-07 13:23:46,607[0;39m [34mINFO [0;39m [[34mmain[0;39m] [33mc.p.k.u.KafkaUiApplication[0;39m: Started KafkaUiApplication in 5.901 seconds (process running for 6.808)
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=1 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=1 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_weather_producer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connected> [IPv4 ('172.20.0.8', 29092)]>: Closing connection. 
upgrade_weather_producer   | INFO:__main__:Sent data for suceava to partition 0
[Kupgrade_weather_consumer exited with code 1
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,449[0;39m [39mDEBUG[0;39m [[34mparallel-2[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,464[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.a.AdminClientConfig[0;39m: AdminClientConfig values: 
upgrade_kafka_ui           | 	auto.include.jmx.reporter = true
upgrade_kafka_ui           | 	bootstrap.servers = [kafka:29092]
upgrade_kafka_ui           | 	client.dns.lookup = use_all_dns_ips
upgrade_kafka_ui           | 	client.id = kafka-ui-admin-1757251427-1
upgrade_kafka_ui           | 	connections.max.idle.ms = 300000
upgrade_kafka_ui           | 	default.api.timeout.ms = 60000
upgrade_kafka_ui           | 	metadata.max.age.ms = 300000
upgrade_kafka_ui           | 	metric.reporters = []
upgrade_kafka_ui           | 	metrics.num.samples = 2
upgrade_kafka_ui           | 	metrics.recording.level = INFO
upgrade_kafka_ui           | 	metrics.sample.window.ms = 30000
upgrade_kafka_ui           | 	receive.buffer.bytes = 65536
upgrade_kafka_ui           | 	reconnect.backoff.max.ms = 1000
upgrade_kafka_ui           | 	reconnect.backoff.ms = 50
upgrade_kafka_ui           | 	request.timeout.ms = 30000
upgrade_kafka_ui           | 	retries = 2147483647
upgrade_kafka_ui           | 	retry.backoff.ms = 100
upgrade_kafka_ui           | 	sasl.client.callback.handler.class = null
upgrade_kafka_ui           | 	sasl.jaas.config = null
upgrade_kafka_ui           | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
upgrade_kafka_ui           | 	sasl.kerberos.min.time.before.relogin = 60000
upgrade_kafka_ui           | 	sasl.kerberos.service.name = null
upgrade_kafka_ui           | 	sasl.kerberos.ticket.renew.jitter = 0.05
upgrade_kafka_ui           | 	sasl.kerberos.ticket.renew.window.factor = 0.8
upgrade_kafka_ui           | 	sasl.login.callback.handler.class = null
upgrade_kafka_ui           | 	sasl.login.class = null
upgrade_kafka_ui           | 	sasl.login.connect.timeout.ms = null
upgrade_kafka_ui           | 	sasl.login.read.timeout.ms = null
upgrade_kafka_ui           | 	sasl.login.refresh.buffer.seconds = 300
upgrade_kafka_ui           | 	sasl.login.refresh.min.period.seconds = 60
upgrade_kafka_ui           | 	sasl.login.refresh.window.factor = 0.8
upgrade_kafka_ui           | 	sasl.login.refresh.window.jitter = 0.05
upgrade_kafka_ui           | 	sasl.login.retry.backoff.max.ms = 10000
upgrade_kafka_ui           | 	sasl.login.retry.backoff.ms = 100
upgrade_kafka_ui           | 	sasl.mechanism = GSSAPI
upgrade_kafka_ui           | 	sasl.oauthbearer.clock.skew.seconds = 30
upgrade_kafka_ui           | 	sasl.oauthbearer.expected.audience = null
upgrade_kafka_ui           | 	sasl.oauthbearer.expected.issuer = null
upgrade_kafka_ui           | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
upgrade_kafka_ui           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
upgrade_kafka_ui           | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
upgrade_kafka_ui           | 	sasl.oauthbearer.jwks.endpoint.url = null
upgrade_kafka_ui           | 	sasl.oauthbearer.scope.claim.name = scope
upgrade_kafka_ui           | 	sasl.oauthbearer.sub.claim.name = sub
upgrade_kafka_ui           | 	sasl.oauthbearer.token.endpoint.url = null
upgrade_kafka_ui           | 	security.protocol = PLAINTEXT
upgrade_kafka_ui           | 	security.providers = null
upgrade_kafka_ui           | 	send.buffer.bytes = 131072
upgrade_kafka_ui           | 	socket.connection.setup.timeout.max.ms = 30000
upgrade_kafka_ui           | 	socket.connection.setup.timeout.ms = 10000
upgrade_kafka_ui           | 	ssl.cipher.suites = null
upgrade_kafka_ui           | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
upgrade_kafka_ui           | 	ssl.endpoint.identification.algorithm = https
upgrade_kafka_ui           | 	ssl.engine.factory.class = null
upgrade_kafka_ui           | 	ssl.key.password = null
upgrade_kafka_ui           | 	ssl.keymanager.algorithm = SunX509
upgrade_kafka_ui           | 	ssl.keystore.certificate.chain = null
upgrade_kafka_ui           | 	ssl.keystore.key = null
upgrade_kafka_ui           | 	ssl.keystore.location = null
upgrade_kafka_ui           | 	ssl.keystore.password = null
upgrade_kafka_ui           | 	ssl.keystore.type = JKS
upgrade_kafka_ui           | 	ssl.protocol = TLSv1.3
upgrade_kafka_ui           | 	ssl.provider = null
upgrade_kafka_ui           | 	ssl.secure.random.implementation = null
upgrade_kafka_ui           | 	ssl.trustmanager.algorithm = PKIX
upgrade_kafka_ui           | 	ssl.truststore.certificates = null
upgrade_kafka_ui           | 	ssl.truststore.location = null
upgrade_kafka_ui           | 	ssl.truststore.password = null
upgrade_kafka_ui           | 	ssl.truststore.type = JKS
upgrade_kafka_ui           | 
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,548[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka version: 3.5.0
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,548[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka commitId: c97b88d5db4de28d
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,548[0;39m [34mINFO [0;39m [[34mparallel-2[0;39m] [33mo.a.k.c.u.AppInfoParser[0;39m: Kafka startTimeMs: 1757251427546
upgrade_weather_producer   | INFO:__main__:Successfully collected weather data for Bucharest
upgrade_weather_producer   | INFO:__main__:Sent data for bucharest to partition 0
upgrade_kafka_ui           | [30m2025-09-07 13:23:47,993[0;39m [39mDEBUG[0;39m [[34mparallel-11[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
upgrade_weather_producer   | INFO:__main__:Successfully collected weather data for Cluj-Napoca
upgrade_weather_producer   | INFO:__main__:Sent data for cluj to partition 0
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_weather_consumer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_consumer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_consumer   | INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('weather-data',)
upgrade_postgres           | 2025-09-07 13:23:49.107 UTC [34] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:23:49.107 UTC [34] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 58, in initialize
upgrade_weather_consumer   |     self.postgres_conn = psycopg2.connect(self.postgres_url)
upgrade_weather_consumer   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/psycopg2/__init__.py", line 122, in connect
upgrade_weather_consumer   |     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
upgrade_weather_consumer   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   | psycopg2.OperationalError: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
[Kupgrade_weather_consumer exited with code 1
upgrade_weather_producer   | INFO:__main__:Successfully collected weather data for Iasi
upgrade_weather_producer   | INFO:__main__:Sent data for iasi to partition 0
upgrade_weather_producer   | INFO:__main__:Successfully collected weather data for Constanta
upgrade_weather_producer   | INFO:__main__:Sent data for constanta to partition 0
upgrade_kafka              | [2025-09-07 13:23:51,415] INFO [Controller id=1] Processing automatic preferred replica leader election (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:51,415] TRACE [Controller id=1] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:51,417] DEBUG [Controller id=1] Topics not in preferred replica for broker 1 Map() (kafka.controller.KafkaController)
upgrade_kafka              | [2025-09-07 13:23:51,418] TRACE [Controller id=1] Leader imbalance ratio for broker 1 is 0.0 (kafka.controller.KafkaController)
upgrade_weather_producer   | INFO:__main__:Collection completed. Success: 5, Failed: 0
upgrade_weather_producer   | INFO:__main__:Producer started. Collecting data every 30 minutes.
upgrade_pgadmin            | NOTE: Configuring authentication for SERVER mode.
upgrade_pgadmin            | 
upgrade_pgadmin            | pgAdmin 4 - Application Initialisation
upgrade_pgadmin            | ======================================
upgrade_pgadmin            | 
upgrade_pgadmin            | postfix/postlog: starting the Postfix mail system
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_weather_consumer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_consumer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_consumer   | INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('weather-data',)
upgrade_postgres           | 2025-09-07 13:23:53.233 UTC [35] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:23:53.233 UTC [35] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 58, in initialize
upgrade_weather_consumer   |     self.postgres_conn = psycopg2.connect(self.postgres_url)
upgrade_weather_consumer   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/psycopg2/__init__.py", line 122, in connect
upgrade_weather_consumer   |     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
upgrade_weather_consumer   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   | psycopg2.OperationalError: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
[Kupgrade_weather_consumer exited with code 1
upgrade_pgadmin            | [2025-09-07 13:23:56 +0000] [1] [INFO] Starting gunicorn 20.1.0
upgrade_pgadmin            | [2025-09-07 13:23:56 +0000] [1] [INFO] Listening at: http://[::]:80 (1)
upgrade_pgadmin            | [2025-09-07 13:23:56 +0000] [1] [INFO] Using worker: gthread
upgrade_pgadmin            | [2025-09-07 13:23:56 +0000] [115] [INFO] Booting worker with pid: 115
upgrade_postgres           | 2025-09-07 13:23:59.355 UTC [36] WARNING:  database "template1" has a collation version mismatch
upgrade_postgres           | 2025-09-07 13:23:59.355 UTC [36] DETAIL:  The database was created using collation version 2.36, but the operating system provides version 2.31.
upgrade_postgres           | 2025-09-07 13:23:59.355 UTC [36] HINT:  Rebuild all objects in this database that use the default collation and run ALTER DATABASE template1 REFRESH COLLATION VERSION, or build PostgreSQL with the right library version.
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_weather_consumer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_consumer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_consumer   | INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('weather-data',)
upgrade_postgres           | 2025-09-07 13:24:00.557 UTC [37] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:00.557 UTC [37] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 58, in initialize
upgrade_weather_consumer   |     self.postgres_conn = psycopg2.connect(self.postgres_url)
upgrade_weather_consumer   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/psycopg2/__init__.py", line 122, in connect
upgrade_weather_consumer   |     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
upgrade_weather_consumer   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   | psycopg2.OperationalError: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
[Kupgrade_weather_consumer exited with code 1
upgrade_postgres           | 2025-09-07 13:24:09.317 UTC [45] FATAL:  role "upgrade" does not exist
upgrade_postgres           | 2025-09-07 13:24:13.860 UTC [46] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:13.860 UTC [46] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:13.885 UTC [47] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:13.885 UTC [47] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:13.979 UTC [48] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:13.979 UTC [48] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:14.004 UTC [49] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:14.004 UTC [49] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:14.034 UTC [50] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:14.034 UTC [50] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:14.085 UTC [51] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:14.085 UTC [51] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | INFO:__main__:Starting Weather Consumer for UPGRADE project
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: connecting to kafka:29092 [('172.20.0.8', 29092) IPv4]
upgrade_weather_consumer   | INFO:kafka.conn:Probing node bootstrap-0 broker version
upgrade_weather_consumer   | INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.20.0.8', 29092)]>: Connection complete.
upgrade_weather_consumer   | INFO:kafka.conn:Broker version identified as 2.5.0
upgrade_weather_consumer   | INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
upgrade_weather_consumer   | INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ('weather-data',)
upgrade_postgres           | 2025-09-07 13:24:14.473 UTC [52] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:14.473 UTC [52] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_weather_consumer   | ERROR:__main__:Failed to initialize consumer: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
upgrade_weather_consumer   | Traceback (most recent call last):
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 371, in <module>
upgrade_weather_consumer   |     main()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 368, in main
upgrade_weather_consumer   |     consumer.start_consumer()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 330, in start_consumer
upgrade_weather_consumer   |     self.initialize()
upgrade_weather_consumer   |   File "/app/weather_consumer.py", line 58, in initialize
upgrade_weather_consumer   |     self.postgres_conn = psycopg2.connect(self.postgres_url)
upgrade_weather_consumer   |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   |   File "/usr/local/lib/python3.11/site-packages/psycopg2/__init__.py", line 122, in connect
upgrade_weather_consumer   |     conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
upgrade_weather_consumer   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
upgrade_weather_consumer   | psycopg2.OperationalError: connection to server at "postgres" (172.20.0.5), port 5432 failed: FATAL:  password authentication failed for user "upgrade"
upgrade_weather_consumer   | 
[Kupgrade_weather_consumer exited with code 1
upgrade_kafka_ui           | [30m2025-09-07 13:24:16,603[0;39m [39mDEBUG[0;39m [[34mparallel-12[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Start getting metrics for kafkaCluster: local
upgrade_kafka_ui           | [30m2025-09-07 13:24:16,617[0;39m [39mDEBUG[0;39m [[34mparallel-17[0;39m] [33mc.p.k.u.s.ClustersStatisticsScheduler[0;39m: Metrics updated for cluster: local
upgrade_postgres           | 2025-09-07 13:24:18.427 UTC [53] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.427 UTC [53] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:18.539 UTC [54] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.539 UTC [54] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:18.553 UTC [55] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.553 UTC [55] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:18.622 UTC [56] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.622 UTC [56] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:18.666 UTC [57] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.666 UTC [57] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:18.736 UTC [58] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:18.736 UTC [58] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:19.356 UTC [59] WARNING:  database "upgrade_db" has a collation version mismatch
upgrade_postgres           | 2025-09-07 13:24:19.356 UTC [59] DETAIL:  The database was created using collation version 2.36, but the operating system provides version 2.31.
upgrade_postgres           | 2025-09-07 13:24:19.356 UTC [59] HINT:  Rebuild all objects in this database that use the default collation and run ALTER DATABASE upgrade_db REFRESH COLLATION VERSION, or build PostgreSQL with the right library version.
upgrade_postgres           | 2025-09-07 13:24:23.025 UTC [60] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.025 UTC [60] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:23.139 UTC [61] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.139 UTC [61] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:23.162 UTC [62] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.162 UTC [62] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:23.221 UTC [63] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.221 UTC [63] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:23.276 UTC [64] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.276 UTC [64] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:23.335 UTC [65] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:23.335 UTC [65] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.689 UTC [66] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.689 UTC [66] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.778 UTC [67] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.778 UTC [67] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.800 UTC [68] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.800 UTC [68] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.836 UTC [69] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.836 UTC [69] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.891 UTC [70] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.891 UTC [70] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
upgrade_postgres           | 2025-09-07 13:24:27.950 UTC [71] FATAL:  password authentication failed for user "upgrade"
upgrade_postgres           | 2025-09-07 13:24:27.950 UTC [71] DETAIL:  Role "upgrade" does not exist.
upgrade_postgres           | 	Connection matched pg_hba.conf line 100: "host all all all scram-sha-256"
